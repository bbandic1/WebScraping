{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Selenium\n",
    "pip install selenium\n",
    "\n",
    "# Remove Chromium browser and install again\n",
    "!apt-get remove chromium-browser\n",
    "!apt-get install chromium-browser\n",
    "!apt-get remove chromium-chromedriver\n",
    "!apt-get install chromium-chromedriver\n",
    "\n",
    "from google.colab import drive\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import pandas as pd\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import re\n",
    "import calendar\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import ElementClickInterceptedException\n",
    "\n",
    "def web_driver():\n",
    "    \"\"\"Create and configure the Chrome WebDriver.\"\"\"\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(\"--verbose\")\n",
    "    options.add_argument('--no-sandbox')\n",
    "    options.add_argument('--headless')\n",
    "    options.add_argument('--disable-gpu')\n",
    "    options.add_argument(\"--window-size=1920, 1200\")\n",
    "    options.add_argument('--disable-dev-shm-usage')\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    return driver\n",
    "\n",
    "# Create WebDriver\n",
    "driver = web_driver()\n",
    "\n",
    "# Static starting URL\n",
    "static_url = \"https://infobiro.ba/publikacije/140/kalendar\"\n",
    "driver.get(static_url)\n",
    "\n",
    "# Check if the page has loaded\n",
    "print(\"Loaded page:\", driver.title)\n",
    "\n",
    "# Define the XPath for the cell with the month to be clicked\n",
    "year_xpath = '//*[@id=\"oo\"]/tbody/tr[20]/td[1]'  # XPath for the year (20th row)\n",
    "cell_xpath = '//*[@id=\"oo\"]/tbody/tr[20]/td[11]/div'  # XPath for the October cell (11th column)\n",
    "\n",
    "try:\n",
    "    # Find the cell with the year (verification step)\n",
    "    year_cell = driver.find_element(By.XPATH, year_xpath)\n",
    "    print(f\"Year found: {year_cell.text}\")\n",
    "\n",
    "    # Find the cell for October (or other month/column if needed)\n",
    "    target_cell = driver.find_element(By.XPATH, cell_xpath)\n",
    "\n",
    "    # Click on the cell using JavaScript\n",
    "    driver.execute_script(\"arguments[0].click();\", target_cell)\n",
    "    print(\"Successfully clicked on the cell with the month value.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "\n",
    "def generate_year_dates(year):\n",
    "    \"\"\"Generate all dates for the specified year in the required format.\"\"\"\n",
    "    base_urls = []\n",
    "\n",
    "    # Iterate through months and days of the year\n",
    "    for month in range(1, 3):  # From January to December\n",
    "        month_name = calendar.month_name[month]\n",
    "\n",
    "        # Determine the number of days in the month\n",
    "        num_days = calendar.monthrange(year, month)[1]\n",
    "\n",
    "        for day in range(1, num_days + 1):  # From the 1st to the last day of the month\n",
    "            # Generate the URL with year, month, and day\n",
    "            base_url = f\"{static_url}/{year}-{month:02}-{day:02}\"\n",
    "            base_urls.append(base_url)\n",
    "            print(f\"Generated base_url: {base_url}\")\n",
    "\n",
    "    return base_urls\n",
    "\n",
    "# Input year\n",
    "year_input = 2024\n",
    "\n",
    "# Print generated dates\n",
    "base_urls = generate_year_dates(year_input)\n",
    "\n",
    "all_links = set()\n",
    "\n",
    "def get_all_article_links(base_url):\n",
    "    \"\"\"Retrieve all article links from the base URL.\"\"\"\n",
    "    # Create WebDriver\n",
    "    driver = web_driver()\n",
    "\n",
    "    huge_page_number = 9999\n",
    "\n",
    "    test_url = f\"{base_url}?page={huge_page_number}\"\n",
    "    print(test_url)\n",
    "\n",
    "    driver.get(test_url)\n",
    "    driver.implicitly_wait(3)\n",
    "\n",
    "    current_url = driver.current_url\n",
    "\n",
    "    # Fetch all links with the text \"Read More\"\n",
    "    page_fault_check = driver.find_elements(By.LINK_TEXT, \"Pročitaj više\")\n",
    "    print(f\"Number of 'Read More' links found during initial testing: {len(page_fault_check)}\")\n",
    "\n",
    "    if len(page_fault_check) == 0:\n",
    "        return set()\n",
    "\n",
    "    page_number_match = re.search(r'page=(\\d+)', current_url)\n",
    "    if page_number_match:\n",
    "        total_pages = int(page_number_match.group(1))  # Extracted page number\n",
    "        print(f\"Page number from URL: {total_pages}\")\n",
    "    else:\n",
    "        print(\"Page number not found in the URL.\")\n",
    "\n",
    "    if total_pages == 9999:\n",
    "        total_pages = 1\n",
    "\n",
    "    all_links = []  # Use a list instead of a set\n",
    "\n",
    "    # Iterate through all pages\n",
    "    for page in range(1, total_pages + 1):\n",
    "        print(f\"Accessing page {page} of {total_pages}...\")\n",
    "\n",
    "        # Form the URL for each page\n",
    "        page_url = f\"{base_url}?page={page}\"\n",
    "        print(f\"Current URL: {page_url}\")  # Log for the current URL\n",
    "\n",
    "        # Open the URL\n",
    "        driver.get(page_url)\n",
    "        driver.implicitly_wait(3)  # Wait for the page to fully load\n",
    "\n",
    "        # Fetch all links with the text \"Read More\"\n",
    "        elements = driver.find_elements(By.LINK_TEXT, \"Pročitaj više\")\n",
    "        print(f\"Number of 'Read More' links found on page {page}: {len(elements)}\")\n",
    "\n",
    "        # Extract absolute URLs\n",
    "        links = [element.get_attribute('href') for element in elements]\n",
    "        all_links.extend(links)  # Add new links to the list\n",
    "\n",
    "        # Pause before moving to the next page\n",
    "        time.sleep(1)\n",
    "\n",
    "    # Close WebDriver\n",
    "    driver.quit()\n",
    "\n",
    "    return all_links\n",
    "\n",
    "article_links = set()\n",
    "for base_url in base_urls:\n",
    "    article_links.update(get_all_article_links(base_url))\n",
    "\n",
    "\n",
    "def get_article_metadata(driver, article_url):\n",
    "    \"\"\"Fetch metadata from the article.\"\"\"\n",
    "    print(f\"Starting to fetch metadata from the article: {article_url}\")\n",
    "    driver.get(article_url)\n",
    "    time.sleep(0.5)\n",
    "\n",
    "    metadata = {\n",
    "        \"newspaper\": \"\",\n",
    "        \"date\": \"\",\n",
    "        \"section\": \"\",\n",
    "        \"header\": \"\",\n",
    "        \"title\": \"\",\n",
    "        \"subtitle\": \"\",\n",
    "        \"page\": \"\",\n",
    "        \"authors\": \"\",\n",
    "        \"text\": \"\"\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        # Newspaper\n",
    "        print(\"Waiting for the newspaper...\")\n",
    "        try:\n",
    "            newspaper_elem = WebDriverWait(driver, 2).until(\n",
    "                EC.presence_of_element_located((By.XPATH, \"//*[@id='article-info-wrapper']/h4/a\"))\n",
    "            ).text\n",
    "            print(f\"Newspaper found: {newspaper_elem}\")\n",
    "            metadata[\"newspaper\"] = newspaper_elem\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching the newspaper: {e}\")\n",
    "            metadata[\"newspaper\"] = \"\"\n",
    "\n",
    "        # Date\n",
    "        print(\"Waiting for the date...\")\n",
    "        try:\n",
    "            date_elem = WebDriverWait(driver, 2).until(EC.presence_of_element_located((By.XPATH, \"//*[@id='article-info-wrapper']/p\"))).text\n",
    "            print(f\"Date found: {date_elem}\")\n",
    "            metadata[\"date\"] = date_elem\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching the date: {e}\")\n",
    "            metadata[\"date\"] = \"\"\n",
    "\n",
    "        # Title\n",
    "        print(\"Waiting for the title...\")\n",
    "        try:\n",
    "            title_elem = WebDriverWait(driver, 2).until(\n",
    "                EC.presence_of_element_located((By.XPATH, \"//*[@id='article-info-wrapper']/h2\"))\n",
    "            ).text\n",
    "            print(f\"Title found: {title_elem}\")\n",
    "            metadata[\"title\"] = title_elem\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching the title: {e}\")\n",
    "            metadata[\"title\"] = \"\"\n",
    "\n",
    "        # Header (can be empty)\n",
    "        try:\n",
    "            print(\"Waiting for the header...\")\n",
    "            header_elem = WebDriverWait(driver, 1).until(\n",
    "                EC.presence_of_element_located((By.XPATH, \"//*[@id='article-info-wrapper']/h5\"))\n",
    "            )\n",
    "            metadata[\"header\"] = header_elem.text.strip()\n",
    "        except Exception as e:\n",
    "            metadata[\"header\"] = \"\"\n",
    "\n",
    "        # Authors\n",
    "        print(\"Waiting for the authors...\")\n",
    "        try:\n",
    "            authors_elem = WebDriverWait(driver, 2).until(\n",
    "                EC.presence_of_element_located((By.XPATH, \"//*[@id='article-info-wrapper']/div[1]/div/span/a\"))\n",
    "            ).text\n",
    "            print(f\"Authors found: {authors_elem}\")\n",
    "            metadata[\"authors\"] = authors_elem\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching the authors: {e}\")\n",
    "            metadata[\"authors\"] = \"\"\n",
    "\n",
    "        # Text\n",
    "        print(\"Waiting for the text...\")\n",
    "        try:\n",
    "            text_elem = WebDriverWait(driver, 2).until(\n",
    "                EC.presence_of_element_located((By.XPATH, \"//*[@id='article-text']\"))\n",
    "            ).text\n",
    "            print(f\"Text found: {text_elem[:100]}...\")  # Show only the first 100 characters for brevity\n",
    "            metadata[\"text\"] = text_elem\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching the text: {e}\")\n",
    "            metadata[\"text\"] = \"\"\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching metadata: {e}\")\n",
    "\n",
    "    return metadata\n",
    "\n",
    "# Function to login to InfoBiro\n",
    "def login_to_infobiro(driver, username, password):\n",
    "    try:\n",
    "        print(\"Opening login page...\")\n",
    "        driver.get(\"https://infobiro.ba/login\")\n",
    "        time.sleep(3)  # Wait for the page to load\n",
    "\n",
    "        # Enter username\n",
    "        print(\"Entering username...\")\n",
    "        username_field = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.XPATH, \"//input[@type='text']\"))\n",
    "        )\n",
    "        username_field.send_keys(username)\n",
    "\n",
    "        # Enter password\n",
    "        print(\"Entering password...\")\n",
    "        password_field = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.XPATH, \"//input[@type='password']\"))\n",
    "        )\n",
    "        password_field.send_keys(password)\n",
    "\n",
    "        # Click login button\n",
    "        print(\"Clicking login button...\")\n",
    "        login_button = WebDriverWait(driver, 10).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, \"//button[contains(text(),'Prijavi se')]\"))\n",
    "        )\n",
    "        try:\n",
    "            login_button.click()\n",
    "        except ElementClickInterceptedException:\n",
    "            driver.execute_script(\"arguments[0].click();\", login_button)\n",
    "\n",
    "        time.sleep(5)  # Wait after login\n",
    "        if driver.current_url == \"https://infobiro.ba/\":\n",
    "            print(\"Login successful!\")\n",
    "        else:\n",
    "            print(\"Login failed! Check username and password.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Login error: {e}\")\n",
    "\n",
    "\n",
    "# Function to fetch metadata for multiple articles\n",
    "def get_multiple_articles_metadata(article_links):\n",
    "    driver = webdriver.Chrome()  # Replace with your specific WebDriver setup\n",
    "    username = \"your_username\"\n",
    "    password = \"your_password\"\n",
    "\n",
    "    login_to_infobiro(driver, username, password)\n",
    "\n",
    "    articles_metadata = []\n",
    "    for index, link in enumerate(article_links, start=1):\n",
    "        print(f\"Fetching metadata for article {index}: {link}\")\n",
    "        metadata = get_article_metadata(driver, link)  # Assuming this function exists\n",
    "        articles_metadata.append(metadata)\n",
    "\n",
    "    driver.quit()\n",
    "    return articles_metadata\n",
    "\n",
    "\n",
    "# Main execution\n",
    "article_links = [...]  # Replace with your article links list\n",
    "articles_data = get_multiple_articles_metadata(article_links)\n",
    "\n",
    "# Save to DataFrame and JSON file\n",
    "df = pd.DataFrame(articles_data)\n",
    "df.to_json(\"Infobiro_Dnevni_Avaz.json\", orient=\"records\", lines=True, force_ascii=False)\n",
    "print(\"Metadata saved to 'Infobiro_Dnevni_Avaz.json'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
